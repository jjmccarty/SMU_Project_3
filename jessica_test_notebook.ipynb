{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import APIChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# Store the API key in a variable.\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text description of API spec.\n",
    "spec_str = \"\"\"\n",
    "\n",
    "Instructions for responding:\n",
    "Use the Open Library Search API to get up to 4 books related to the person the book is requested for.  \n",
    "Provide the response to the user with the title and author of the books in natural language. \n",
    "Ask the user if they want more information about a book\n",
    "\n",
    "If the user asks for information about a book by the title, use Open Library Search API to get summary of the book between 100 and 200 words in length and provide a list of up to 4 similar books.\n",
    "\n",
    "If the user asks for information about the author, use Open Libaray Search API to get information about the author.  Also provide up to 5 more books written by the author.\n",
    "\n",
    "\n",
    "Open Library provides an experimental API to search.\n",
    "\n",
    "WARNING: This API is under active development and may change in future.\n",
    "\n",
    "Overview & Features\n",
    "The Open Library Search API is one of the most convenient and complete ways to retrieve book data on Open Library. The API:\n",
    "\n",
    "Is able to return data for multiple books in a single request/response\n",
    "Returns both Work level information about the book, as well as Edition level information (such as)\n",
    "Author IDs are returned which you can use to fetch the author's image, if available\n",
    "Options are available to return Book Availability along with the response.\n",
    "Powerful sorting options are available, such as star ratings, publication date, and number of editions.\n",
    "Endpoint\n",
    "The endpoint for this API is:\n",
    "https://openlibrary.org/search.json\n",
    "\n",
    "Examples\n",
    "The URL format for API is simple. Take the search URL and add .json to the end. Eg:\n",
    "\n",
    "https://openlibrary.org/search.json?q=the+lord+of+the+rings\n",
    "https://openlibrary.org/search.json?title=the+lord+of+the+rings\n",
    "https://openlibrary.org/search.json?author=tolkien&sort=new\n",
    "https://openlibrary.org/search.json?q=the+lord+of+the+rings&page=2\n",
    "https://openlibrary.org/search/authors.json?q=twain\n",
    "Using Thing IDs to get Images\n",
    "You can use the olid (Open Library ID) for authors and books to fetch covers by olid, e.g.:\n",
    "https://covers.openlibrary.org/a/olid/OL23919A-M.jpg\n",
    "\n",
    "URL Parameters\n",
    "Parameter\tDescription\n",
    "q\tThe solr query. See Search HowTo for sample queries\n",
    "fields\tThe fields to get back from solr. Use the special value * to get all fields (although be prepared for a very large response!).\n",
    "To fetch availability data from archive.org, add the special value, availability. Example: /search.json?q=harry%20potter&fields=*,availability&limit=1. This will fetch the availability data of the first item in the `ia` field.\n",
    "sort\tYou can sort the results by various facets such as new, old, random, or key (which sorts as a string, not as the number stored in the string). For a complete list of sorts facets look here (this link goes to a specific commit, be sure to look at the latest one for changes). The default is to sort by relevance.\n",
    "lang\tThe users language as a two letter (ISO 639-1) language code. This influences but doesn't exclude search results. For example setting this to fr will prefer/display the French edition of a given work, but will still match works that don't have French editions. Adding language:fre on the other hand to the search query will exclude results that don't have a French edition.\n",
    "offset / limit\tUse for pagination.\n",
    "page / limit\tUse for pagination, with limit corresponding to the page size. Note page starts at 1.\n",
    "Include no other text, only the API call URL. Don't use newlines.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes in a message.\n",
    "def run(msg, history):\n",
    "     # Define a query as a dictionary using the user's input.\n",
    "    query = {\"question\": msg}\n",
    "\n",
    "\n",
    "# Create the API chain from the spec, using the LLM.\n",
    "    chain = APIChain.from_llm_and_api_docs(\n",
    "    llm,\n",
    "    spec_str,\n",
    "    #verbose = True,\n",
    "    limit_to_domains=[\"https://openlibrary.org/\"],\n",
    "    )\n",
    "    try:\n",
    "        # Run the chain using the query, and print the response.\n",
    "        response = chain.invoke(query)\n",
    "        #print(response[\"output\"])\n",
    "        return response[\"output\"]\n",
    "    except:\n",
    "        return \"Sorry, that query generated too large of a result. Please try a different question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the Gradio Interface application function with the following parameters.\n",
    "#app = gr.Interface(fn=run, inputs=\"text\", outputs=\"text\")\n",
    "app = gr.ChatInterface(fn=run, type=\"messages\")\n",
    "\n",
    "# Launch the app\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
